# ğŸ¢ Sea### Objectifs Globaux du SystÃ¨me

-   **PrÃ©diction Ã©nergÃ©tique** : DÃ©velopper d**ModÃ¨les comparÃ©s :**
-   **Linear Regression** : ModÃ¨le de rÃ©fÃ©rence linÃ©aire
-   **SVR (Support Vector Regressor)** : ModÃ¨le non-linÃ©aire avec kernel RBF
-   **Random Forest** : ModÃ¨le d'ensemble basÃ© sur les arbres
-   **Gradient Boosting** : ModÃ¨le d'ensemble avec boosting sÃ©quentiel

**Ã‰valuation :**

-   Validation croisÃ©e 5-folds avec stratÃ©gie cohÃ©rente (`KFold`)
-   MÃ©triques : RÂ², MAE, RMSE
-   Analyse du surapprentissage
-   Comparaison Ã©quitable avec mÃªmes splits CVML pour prÃ©dire les Ã©missions de GES des bÃ¢timents
-   **Analyse des facteurs** : Identifier les caractÃ©ristiques des bÃ¢timents qui influencent le plus les Ã©missions
-   **Comparaison de modÃ¨les** : Ã‰valuer plusieurs algorithmes (Linear Regression, SVR, Random Forest, Gradient Boosting) pour dÃ©terminer le plus performant

### 4. Optimisation

-   Grid Search pour l'optimisation des hyperparamÃ¨tres
-   Optimisation de Random Forest et Gradient Boosting
-   Validation avec stratÃ©gie CV cohÃ©rente
-   Analyse de l'importance des features
-   SystÃ¨me de prÃ©diction pour nouveaux bÃ¢timents
-   **InfÃ©rence** : DÃ©velopper un systÃ¨me de prÃ©diction pour de nouveaux bÃ¢timentsuilding Energy Consumption Prediction

Un projet de machine learning pour prÃ©dire la consommation Ã©nergÃ©tique et les Ã©missions de GES des bÃ¢timents de Seattle basÃ© sur les donnÃ©es du programme de benchmarking Ã©nergÃ©tique de la ville.

## ğŸ“‹ Contexte du Projet

Ce projet analyse les donnÃ©es du programme de benchmarking Ã©nergÃ©tique de Seattle pour dÃ©velopper des modÃ¨les prÃ©dictifs de consommation Ã©nergÃ©tique. Le dataset contient des informations dÃ©taillÃ©es sur plus de 3000 bÃ¢timents de Seattle, incluant leurs caractÃ©ristiques physiques, leur usage, et leur performance Ã©nergÃ©tique.

### Objectifs Globaux du SystÃ¨me

-   **PrÃ©diction Ã©nergÃ©tique** : DÃ©velopper des modÃ¨les ML pour prÃ©dire la consommation Ã©nergÃ©tique des bÃ¢timents
-   **Analyse des facteurs** : Identifier les caractÃ©ristiques des bÃ¢timents qui influencent le plus la consommation
-   **Comparaison de modÃ¨les** : Ã‰valuer plusieurs algorithmes (Linear Regression, SVR, Random Forest) pour dÃ©terminer le plus performant
-   **Optimisation** : AmÃ©liorer les performances du meilleur modÃ¨le via l'optimisation des hyperparamÃ¨tres

## ğŸ—‚ï¸ Structure du Projet

```
â”œâ”€â”€ assets/                                    # DonnÃ©es et fichiers de ressources
â”‚   â”œâ”€â”€ 2016_Building_Energy_Benchmarking.csv # Dataset original (3000+ bÃ¢timents)
â”‚   â”œâ”€â”€ building_consumption_post_EDA.csv     # DonnÃ©es aprÃ¨s analyse exploratoire et nettoyage
â”‚   â”œâ”€â”€ building_consumption_post_feature_engineering.csv # DonnÃ©es avec nouvelles features
â”‚   â””â”€â”€ building_consumption_cleaned.csv      # DonnÃ©es finales prÃªtes pour modÃ©lisation
â”œâ”€â”€ notebooks/                                # Notebooks Jupyter d'analyse
â”‚   â”œâ”€â”€ 1. EDA.ipynb                         # Analyse exploratoire
â”‚   â”œâ”€â”€ 2. Feature Engineering.ipynb         # IngÃ©nierie des features
â”‚   â”œâ”€â”€ 3. PrÃ©paration des features.ipynb    # PrÃ©paration finale des donnÃ©es
â”‚   â”œâ”€â”€ 4. Comparaison des diffÃ©rents modÃ¨les.ipynb # Comparaison de modÃ¨les
â”‚   â””â”€â”€ 5. Optimisation du modÃ¨le.ipynb      # Optimisation des hyperparamÃ¨tres
â”œâ”€â”€ src/                                      # Code source Python (si applicable)
â”œâ”€â”€ config.py                                # Configuration (variable cible, etc.)
â”œâ”€â”€ requirements.txt                          # DÃ©pendances Python
â””â”€â”€ README.md                                # Documentation du projet
```

## ğŸ¯ Variables Cibles

Le projet explore deux variables cibles principales :

-   **`SiteEnergyUseWN(kBtu)`** : Consommation Ã©nergÃ©tique du site (normalisÃ©e mÃ©tÃ©o)
-   **`TotalGHGEmissions`** : Ã‰missions totales de gaz Ã  effet de serre

_Variable actuellement configurÃ©e_ : `TotalGHGEmissions` (voir `config.py`)

## ğŸ“Š Dataset

**Source** : Seattle Building Energy Benchmarking Program 2016

-   **Taille** : ~3000+ bÃ¢timents
-   **Features** : CaractÃ©ristiques des bÃ¢timents (surface, Ã¢ge, usage, etc.)
-   **Cible** : Consommation Ã©nergÃ©tique / Ã‰missions GES

### Pipeline de DonnÃ©es

```
2016_Building_Energy_Benchmarking.csv (Original)
    â†“ [EDA + Nettoyage]
building_consumption_post_EDA.csv
    â†“ [Feature Engineering]
building_consumption_post_feature_engineering.csv
    â†“ [PrÃ©paration finale]
building_consumption_cleaned.csv (ModÃ©lisation)
```

### Principales caractÃ©ristiques analysÃ©es :

-   Surface du bÃ¢timent (`PropertyGFABuilding`)
-   AnnÃ©e de construction (`YearBuilt`)
-   Type d'usage (`PrimaryPropertyType`)
-   Score ENERGY STAR (`ENERGYSTARScore`)
-   IntensitÃ© Ã©nergÃ©tique (`SiteEnergyUseIntensity`)

## ï¿½ MÃ©thodologie

### 1. Analyse Exploratoire (EDA)

-   Distribution des variables
-   CorrÃ©lations entre features
-   DÃ©tection des valeurs aberrantes
-   Analyse des donnÃ©es manquantes

### 2. Feature Engineering

-   Nettoyage des donnÃ©es
-   Traitement des valeurs manquantes
-   Encodage des variables catÃ©gorielles
-   Normalisation des features numÃ©riques

### 3. ModÃ©lisation

**ModÃ¨les comparÃ©s :**

-   **Linear Regression** : ModÃ¨le de rÃ©fÃ©rence linÃ©aire
-   **SVR (Support Vector Regressor)** : ModÃ¨le non-linÃ©aire avec kernel RBF
-   **Random Forest** : ModÃ¨le d'ensemble basÃ© sur les arbres

**Ã‰valuation :**

-   Validation croisÃ©e 5-folds
-   MÃ©triques : RÂ², MAE, RMSE
-   Analyse du surapprentissage

### 4. Optimisation

-   Grid Search pour l'optimisation des hyperparamÃ¨tres
-   Validation sur donnÃ©es de test
-   Analyse de l'importance des features

## âš™ï¸ Installation et Usage

### PrÃ©requis

```bash
Python 3.8+
Jupyter Notebook
```

### Installation

```bash
# Cloner le repository
git clone https://github.com/XavierCoulon/OC_P3_Seattle_Buildings_Consumption.git
cd OC_P3_Seattle_Buildings_Consumption

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer Jupyter
jupyter notebook
```

### Utilisation

1. **Commencer par l'EDA** : Ouvrir `1. EDA.ipynb` pour explorer les donnÃ©es
2. **Feature Engineering** : Suivre les notebooks 2 et 3 pour la prÃ©paration
3. **ModÃ©lisation** : Utiliser le notebook 4 pour comparer les modÃ¨les
4. **Optimisation** : Notebook 5 pour amÃ©liorer le meilleur modÃ¨le
5. **PrÃ©diction** : Utiliser la fonction `predict_building_energy()` pour de nouveaux bÃ¢timents

## ğŸ“ˆ RÃ©sultats Principaux

### Comparaison des ModÃ¨les

| ModÃ¨le                | RÂ² Test   | MAE Test | RMSE Test | Surapprentissage    |
| --------------------- | --------- | -------- | --------- | ------------------- |
| **Linear Regression** | 0.363     | 182      | 438       | Faible (0.088)      |
| **SVR**               | -0.024    | 135      | 566       | TrÃ¨s faible (0.002) |
| **Random Forest**     | 0.551     | 110      | 364       | ModÃ©rÃ© (0.379)      |
| **Gradient Boosting** | **0.657** | **107**  | **310**   | ModÃ©rÃ© (0.309)      |

### Optimisation des HyperparamÃ¨tres

| ModÃ¨le                              | Configuration                          | RÂ² Test   | AmÃ©lioration |
| ----------------------------------- | -------------------------------------- | --------- | ------------ |
| **Random Forest (Baseline)**        | n_estimators=100, max_depth=20         | 0.543     | -            |
| **Random Forest (OptimisÃ©)**        | n_estimators=500, max_depth=20         | 0.551     | +0.008       |
| **Gradient Boosting (Baseline)**    | n_estimators=200, max_depth=3, lr=0.1  | 0.655     | +0.112       |
| **ğŸ† Gradient Boosting (OptimisÃ©)** | n_estimators=300, max_depth=3, lr=0.05 | **0.657** | **+0.114**   |

### Insights ClÃ©s

-   **ğŸ† Meilleur modÃ¨le** : **Gradient Boosting OptimisÃ©** (RÂ² = 0.657)
-   **ğŸ“Š Performance** : Explique 65.7% de la variance des Ã©missions GES
-   **ğŸ”§ Optimisation efficace** : +11.4% d'amÃ©lioration vs Random Forest baseline
-   **âš–ï¸ Ã‰quilibre optimal** : Bon compromis performance/surapprentissage
-   **ğŸ“ˆ Features importantes** :
    -   `NumberofBuildings` (importance: ~38%)
    -   `PropertyGFABuilding(s)` (importance: ~31%)
    -   `ENERGYSTARScore` (importance: ~6%)
-   **ğŸ¯ CapacitÃ© de prÃ©diction** : SystÃ¨me fonctionnel pour nouveaux bÃ¢timents

## ğŸ› ï¸ Technologies UtilisÃ©es

-   **Python 3.8+** : Langage principal
-   **Pandas** : Manipulation des donnÃ©es
-   **Scikit-learn** : Machine Learning
-   **NumPy** : Calculs numÃ©riques
-   **Matplotlib/Seaborn** : Visualisations
-   **Jupyter** : Environnement de dÃ©veloppement

## ğŸ“ Configuration

Le fichier `config.py` permet de configurer facilement la variable cible :

```python
# Changer la variable cible
TARGET = "SiteEnergyUseWN(kBtu)"  # ou "TotalGHGEmissions"
```

## ğŸ¤ Contribution

Ce projet fait partie du parcours OpenClassrooms AI Engineer.
Pour contribuer :

1. Fork le projet
2. CrÃ©er une branche feature
3. Commit les changements
4. Push sur la branche
5. CrÃ©er une Pull Request

## ğŸ“„ Licence

Projet Ã©ducatif dans le cadre du parcours OpenClassrooms AI Engineer.

## ğŸ“ Contact

**Xavier Coulon** - Ã‰tudiant AI Engineer

-   GitHub : [@XavierCoulon](https://github.com/XavierCoulon)

---

_Projet rÃ©alisÃ© dans le cadre du Projet 3 - Parcours AI Engineering OpenClassrooms_
