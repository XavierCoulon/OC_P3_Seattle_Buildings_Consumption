{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, \n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Preprocess\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Mod√®les\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import config\n",
    "\n",
    "importlib.reload(config)  # Ensure we get the latest TARGET value\n",
    "from config import TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation et interpr√©tation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A r√©aliser :\n",
    "* Reprennez le meilleur algorithme que vous avez s√©curis√© via l'√©tape pr√©c√©dente, et r√©alisez une GridSearch de petite taille sur au moins 3 hyperparam√®tres.\n",
    "* Si le meilleur mod√®le fait partie de la famille des mod√®les √† arbres (RandomForest, GradientBoosting) alors utilisez la fonctionnalit√© feature importance pour identifier les features les plus impactantes sur la performance du mod√®le. Sinon, utilisez la m√©thode Permutation Importance de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NumberofBuildings', 'PropertyGFAParking', 'PropertyGFABuilding(s)',\n",
       "       'ENERGYSTARScore', 'TotalGHGEmissions', 'NumberOfUseTypes', 'SteamUse',\n",
       "       'NaturalGas', 'Electricity', 'PrimaryPropertyType_0',\n",
       "       'PrimaryPropertyType_1', 'PrimaryPropertyType_2',\n",
       "       'PrimaryPropertyType_3', 'PrimaryPropertyType_4',\n",
       "       'BuildingType_Nonresidential COS', 'BuildingType_Nonresidential WA',\n",
       "       'BuildingType_SPS-District K-12', 'NumberofFloors_quintile_Q2',\n",
       "       'NumberofFloors_quintile_Q3', 'NumberofFloors_quintile_Q4',\n",
       "       'NumberofFloors_quintile_Q5', 'EraBuilt_1951-1970',\n",
       "       'EraBuilt_1971-1990', 'EraBuilt_1991-2010', 'EraBuilt_Post-2010',\n",
       "       'EraBuilt_‚â§1930'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "building_consumption = pd.read_csv(\"../assets/building_consumption_cleaned.csv\")\n",
    "building_consumption.head()\n",
    "building_consumption.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Meilleurs hyperparam√®tres : {'model__max_depth': 20, 'model__min_samples_split': 2, 'model__n_estimators': 500}\n",
      "Meilleur R¬≤ : 0.5506112567376276\n",
      "Meilleurs hyperparam√®tres : {'model__max_depth': 20, 'model__min_samples_split': 2, 'model__n_estimators': 500}\n",
      "Meilleur R¬≤ : 0.5506112567376276\n",
      "Baseline R¬≤ (same as notebook 4): 0.543\n",
      "                       feature  importance\n",
      "0            NumberofBuildings    0.383363\n",
      "2       PropertyGFABuilding(s)    0.313106\n",
      "3              ENERGYSTARScore    0.064271\n",
      "19  NumberofFloors_quintile_Q5    0.039199\n",
      "10       PrimaryPropertyType_2    0.027266\n",
      "6                   NaturalGas    0.026976\n",
      "9        PrimaryPropertyType_1    0.019893\n",
      "5                     SteamUse    0.018582\n",
      "4             NumberOfUseTypes    0.017750\n",
      "11       PrimaryPropertyType_3    0.012983\n",
      "Baseline R¬≤ (same as notebook 4): 0.543\n",
      "                       feature  importance\n",
      "0            NumberofBuildings    0.383363\n",
      "2       PropertyGFABuilding(s)    0.313106\n",
      "3              ENERGYSTARScore    0.064271\n",
      "19  NumberofFloors_quintile_Q5    0.039199\n",
      "10       PrimaryPropertyType_2    0.027266\n",
      "6                   NaturalGas    0.026976\n",
      "9        PrimaryPropertyType_1    0.019893\n",
      "5                     SteamUse    0.018582\n",
      "4             NumberOfUseTypes    0.017750\n",
      "11       PrimaryPropertyType_3    0.012983\n"
     ]
    }
   ],
   "source": [
    "# Pr√©processor : toutes les features sont num√©riques et encod√©es\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "# Import the same CV strategy from notebook 4\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Use the same CV strategy as notebook 4\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Pipeline RandomForest - match exactly notebook 4 configuration\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"model\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparam√®tres √† tester\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [100, 300, 500],  # nombre d'arbres\n",
    "    \"model__max_depth\": [None, 5, 10, 20],  # profondeur max\n",
    "    \"model__min_samples_split\": [2, 5, 10],  # nb min d'√©chantillons pour splitter\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_rf, param_grid, cv=cv_strategy, scoring=\"r2\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "# On s√©pare X et y\n",
    "X = building_consumption.drop(columns=[TARGET])\n",
    "y = building_consumption[TARGET]\n",
    "\n",
    "# Lancement de la recherche\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Meilleurs hyperparam√®tres :\", grid_search.best_params_)\n",
    "print(\"Meilleur R¬≤ :\", grid_search.best_score_)\n",
    "\n",
    "# Verify baseline: test the exact same config as notebook 4\n",
    "baseline_rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=20, min_samples_split=2)\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "baseline_cv = cross_validate(\n",
    "    baseline_rf, X, y, cv=cv_strategy, scoring=\"r2\", return_train_score=True\n",
    ")\n",
    "print(f\"Baseline R¬≤ (same as notebook 4): {baseline_cv['test_score'].mean():.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "best_model = grid_search.best_estimator_.named_steps[\"model\"]\n",
    "importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "feat_imp_df = pd.DataFrame(\n",
    "    {\"feature\": feature_names, \"importance\": importances}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(feat_imp_df.head(10))  # top 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation GradientBoostingRegressor\n",
    "\n",
    "Maintenant, testons √©galement l'optimisation du GradientBoostingRegressor qui a montr√© de bonnes performances dans le notebook de comparaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration de la grille de recherche pour GradientBoosting:\n",
      "Nombre total de combinaisons: 81\n",
      "Param√®tres test√©s:\n",
      "  model__n_estimators: [100, 200, 300]\n",
      "  model__max_depth: [3, 5, 7]\n",
      "  model__learning_rate: [0.05, 0.1, 0.15]\n",
      "  model__subsample: [0.8, 0.9, 1.0]\n",
      "\n",
      "üöÄ Lancement de l'optimisation GradientBoosting...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "=== R√âSULTATS GRADIENTBOOSTING ===\n",
      "Meilleurs hyperparam√®tres : {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 300, 'model__subsample': 1.0}\n",
      "Meilleur R¬≤ : 0.6572789503131984\n",
      "Baseline R¬≤ (notebook 4): 0.655\n",
      "Am√©lioration: +0.003 points R¬≤\n"
     ]
    }
   ],
   "source": [
    "# Pipeline GradientBoosting\n",
    "pipeline_gb = Pipeline([\n",
    "    (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparam√®tres optimaux pour GradientBoosting\n",
    "# Bas√© sur les meilleures pratiques et la performance attendue\n",
    "param_grid_gb = {\n",
    "    # Nombre d'estimateurs (arbres) - commence mod√©r√© pour √©viter overfitting\n",
    "    \"model__n_estimators\": [100, 200, 300],\n",
    "    \n",
    "    # Profondeur des arbres - g√©n√©ralement plus faible que RandomForest\n",
    "    \"model__max_depth\": [3, 5, 7],\n",
    "    \n",
    "    # Taux d'apprentissage - tr√®s important pour GradientBoosting\n",
    "    \"model__learning_rate\": [0.05, 0.1, 0.15],\n",
    "    \n",
    "    # Fraction d'√©chantillons utilis√©s pour chaque arbre (subsample)\n",
    "    \"model__subsample\": [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "print(\"Configuration de la grille de recherche pour GradientBoosting:\")\n",
    "print(f\"Nombre total de combinaisons: {len(param_grid_gb['model__n_estimators']) * len(param_grid_gb['model__max_depth']) * len(param_grid_gb['model__learning_rate']) * len(param_grid_gb['model__subsample'])}\")\n",
    "print(\"Param√®tres test√©s:\")\n",
    "for param, values in param_grid_gb.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "grid_search_gb = GridSearchCV(\n",
    "    pipeline_gb, \n",
    "    param_grid_gb, \n",
    "    cv=cv_strategy, \n",
    "    scoring=\"r2\", \n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Lancement de la recherche pour GradientBoosting\n",
    "print(\"\\nüöÄ Lancement de l'optimisation GradientBoosting...\")\n",
    "grid_search_gb.fit(X, y)\n",
    "\n",
    "print(\"\\n=== R√âSULTATS GRADIENTBOOSTING ===\")\n",
    "print(\"Meilleurs hyperparam√®tres :\", grid_search_gb.best_params_)\n",
    "print(\"Meilleur R¬≤ :\", grid_search_gb.best_score_)\n",
    "\n",
    "# Comparaison avec le baseline de notebook 4\n",
    "baseline_gb = GradientBoostingRegressor(n_estimators=200, random_state=42, max_depth=3, learning_rate=0.1)\n",
    "baseline_cv_gb = cross_validate(\n",
    "    baseline_gb, X, y, cv=cv_strategy, scoring=\"r2\", return_train_score=True\n",
    ")\n",
    "print(f\"Baseline R¬≤ (notebook 4): {baseline_cv_gb['test_score'].mean():.3f}\")\n",
    "print(f\"Am√©lioration: +{grid_search_gb.best_score_ - baseline_cv_gb['test_score'].mean():.3f} points R¬≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 10 FEATURES IMPORTANTES (GradientBoosting) ===\n",
      "                       feature  importance\n",
      "0            NumberofBuildings    0.392791\n",
      "2       PropertyGFABuilding(s)    0.360606\n",
      "19  NumberofFloors_quintile_Q5    0.105114\n",
      "3              ENERGYSTARScore    0.033338\n",
      "12       PrimaryPropertyType_4    0.026040\n",
      "9        PrimaryPropertyType_1    0.017342\n",
      "5                     SteamUse    0.014651\n",
      "11       PrimaryPropertyType_3    0.007713\n",
      "6                   NaturalGas    0.007140\n",
      "1           PropertyGFAParking    0.006713\n",
      "\n",
      "=== COMPARAISON FEATURE IMPORTANCE ===\n",
      "                       feature  RF_importance  GB_importance  difference\n",
      "3            NumberofBuildings       0.383363       0.392791   -0.009428\n",
      "9       PropertyGFABuilding(s)       0.313106       0.360606   -0.047500\n",
      "0              ENERGYSTARScore       0.064271       0.033338    0.030933\n",
      "4   NumberofFloors_quintile_Q5       0.039199       0.105114   -0.065915\n",
      "6        PrimaryPropertyType_2       0.027266       0.000000    0.027266\n",
      "1                   NaturalGas       0.026976       0.007140    0.019835\n",
      "5        PrimaryPropertyType_1       0.019893       0.017342    0.002550\n",
      "11                    SteamUse       0.018582       0.014651    0.003931\n",
      "2             NumberOfUseTypes       0.017750       0.000000    0.017750\n",
      "7        PrimaryPropertyType_3       0.012983       0.007713    0.005271\n",
      "8        PrimaryPropertyType_4       0.000000       0.026040   -0.026040\n",
      "10          PropertyGFAParking       0.000000       0.006713   -0.006713\n"
     ]
    }
   ],
   "source": [
    "# Feature importance pour GradientBoosting\n",
    "best_model_gb = grid_search_gb.best_estimator_.named_steps[\"model\"]\n",
    "importances_gb = best_model_gb.feature_importances_\n",
    "\n",
    "feat_imp_df_gb = pd.DataFrame(\n",
    "    {\"feature\": feature_names, \"importance\": importances_gb}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 10 FEATURES IMPORTANTES (GradientBoosting) ===\")\n",
    "print(feat_imp_df_gb.head(10))\n",
    "\n",
    "# Comparaison des feature importances entre RandomForest et GradientBoosting\n",
    "print(\"\\n=== COMPARAISON FEATURE IMPORTANCE ===\")\n",
    "comparison_df = pd.merge(\n",
    "    feat_imp_df.head(10)[['feature', 'importance']].rename(columns={'importance': 'RF_importance'}),\n",
    "    feat_imp_df_gb.head(10)[['feature', 'importance']].rename(columns={'importance': 'GB_importance'}),\n",
    "    on='feature', \n",
    "    how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "comparison_df['difference'] = comparison_df['RF_importance'] - comparison_df['GB_importance']\n",
    "comparison_df = comparison_df.sort_values('RF_importance', ascending=False)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison finale des mod√®les optimis√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARAISON FINALE DES MOD√àLES OPTIMIS√âS ===\n",
      "                     Mod√®le                                                    Configuration  R¬≤ Score  Am√©lioration\n",
      "    RandomForest (Baseline)              n_estimators=100, max_depth=20, min_samples_split=2    0.5429        0.0000\n",
      "    RandomForest (Optimis√©)              n_estimators=500, max_depth=20, min_samples_split=2    0.5506        0.0077\n",
      "GradientBoosting (Baseline)                 n_estimators=200, max_depth=3, learning_rate=0.1    0.6545        0.1117\n",
      "GradientBoosting (Optimis√©) n_estimators=300, max_depth=3, learning_rate=0.05, subsample=1.0    0.6573        0.1144\n",
      "\n",
      "üèÜ MEILLEUR MOD√àLE: GradientBoosting (Optimis√©)\n",
      "üìä Score R¬≤: 0.6573\n",
      "üìã Configuration optimale: {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 300, 'model__subsample': 1.0}\n",
      "\n",
      "üí° Am√©lioration vs baseline RandomForest: +0.1144 points R¬≤\n"
     ]
    }
   ],
   "source": [
    "# Tableau de comparaison final\n",
    "results_summary = pd.DataFrame({\n",
    "    'Mod√®le': ['RandomForest (Baseline)', 'RandomForest (Optimis√©)', 'GradientBoosting (Baseline)', 'GradientBoosting (Optimis√©)'],\n",
    "    'Configuration': [\n",
    "        'n_estimators=100, max_depth=20, min_samples_split=2',\n",
    "        f\"n_estimators={grid_search.best_params_['model__n_estimators']}, max_depth={grid_search.best_params_['model__max_depth']}, min_samples_split={grid_search.best_params_['model__min_samples_split']}\",\n",
    "        'n_estimators=200, max_depth=3, learning_rate=0.1',\n",
    "        f\"n_estimators={grid_search_gb.best_params_['model__n_estimators']}, max_depth={grid_search_gb.best_params_['model__max_depth']}, learning_rate={grid_search_gb.best_params_['model__learning_rate']}, subsample={grid_search_gb.best_params_['model__subsample']}\"\n",
    "    ],\n",
    "    'R¬≤ Score': [\n",
    "        baseline_cv['test_score'].mean(),\n",
    "        grid_search.best_score_,\n",
    "        baseline_cv_gb['test_score'].mean(),\n",
    "        grid_search_gb.best_score_\n",
    "    ],\n",
    "    'Am√©lioration': [\n",
    "        0,  # baseline\n",
    "        grid_search.best_score_ - baseline_cv['test_score'].mean(),\n",
    "        baseline_cv_gb['test_score'].mean() - baseline_cv['test_score'].mean(),  # vs RF baseline\n",
    "        grid_search_gb.best_score_ - baseline_cv['test_score'].mean()  # vs RF baseline\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_summary['R¬≤ Score'] = results_summary['R¬≤ Score'].round(4)\n",
    "results_summary['Am√©lioration'] = results_summary['Am√©lioration'].round(4)\n",
    "\n",
    "print(\"=== COMPARAISON FINALE DES MOD√àLES OPTIMIS√âS ===\")\n",
    "print(results_summary.to_string(index=False))\n",
    "\n",
    "# D√©terminer le meilleur mod√®le\n",
    "best_model_idx = results_summary['R¬≤ Score'].idxmax()\n",
    "best_model_name = results_summary.loc[best_model_idx, 'Mod√®le']\n",
    "best_score = results_summary.loc[best_model_idx, 'R¬≤ Score']\n",
    "\n",
    "print(f\"\\nüèÜ MEILLEUR MOD√àLE: {best_model_name}\")\n",
    "print(f\"üìä Score R¬≤: {best_score:.4f}\")\n",
    "\n",
    "if 'RandomForest' in best_model_name:\n",
    "    print(f\"üìã Configuration optimale: {grid_search.best_params_}\")\n",
    "    final_model = grid_search.best_estimator_\n",
    "else:\n",
    "    print(f\"üìã Configuration optimale: {grid_search_gb.best_params_}\")\n",
    "    final_model = grid_search_gb.best_estimator_\n",
    "\n",
    "print(f\"\\nüí° Am√©lioration vs baseline RandomForest: +{best_score - baseline_cv['test_score'].mean():.4f} points R¬≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©diction sur de nouveaux b√¢timents\n",
    "\n",
    "Maintenant que nous avons un mod√®le optimis√©, voyons comment l'utiliser pour faire des pr√©dictions sur des b√¢timents inconnus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features requises pour la pr√©diction:\n",
      "['NumberofBuildings', 'PropertyGFAParking', 'PropertyGFABuilding(s)', 'ENERGYSTARScore', 'NumberOfUseTypes', 'SteamUse', 'NaturalGas', 'Electricity', 'PrimaryPropertyType_0', 'PrimaryPropertyType_1', 'PrimaryPropertyType_2', 'PrimaryPropertyType_3', 'PrimaryPropertyType_4', 'BuildingType_Nonresidential COS', 'BuildingType_Nonresidential WA', 'BuildingType_SPS-District K-12', 'NumberofFloors_quintile_Q2', 'NumberofFloors_quintile_Q3', 'NumberofFloors_quintile_Q4', 'NumberofFloors_quintile_Q5', 'EraBuilt_1951-1970', 'EraBuilt_1971-1990', 'EraBuilt_1991-2010', 'EraBuilt_Post-2010', 'EraBuilt_‚â§1930']\n",
      "\n",
      "Nombre total de features: 25\n"
     ]
    }
   ],
   "source": [
    "def predict_building_energy(building_data, model=grid_search.best_estimator_):\n",
    "    \"\"\"\n",
    "    Pr√©dit la consommation √©nerg√©tique d'un ou plusieurs b√¢timents\n",
    "    \n",
    "    Args:\n",
    "        building_data: DataFrame ou dict avec les caract√©ristiques du/des b√¢timent(s)\n",
    "        model: Mod√®le entra√Æn√© (par d√©faut le meilleur mod√®le de GridSearch)\n",
    "    \n",
    "    Returns:\n",
    "        Pr√©diction(s) de consommation √©nerg√©tique\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Convertir en DataFrame si c'est un dictionnaire\n",
    "    if isinstance(building_data, dict):\n",
    "        building_data = pd.DataFrame([building_data])\n",
    "    \n",
    "    # V√©rifier que toutes les features n√©cessaires sont pr√©sentes\n",
    "    required_features = X.columns.tolist()\n",
    "    missing_features = set(required_features) - set(building_data.columns)\n",
    "    \n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Features manquantes: {missing_features}\")\n",
    "    \n",
    "    # S'assurer que les colonnes sont dans le bon ordre\n",
    "    building_data = building_data[required_features]\n",
    "    \n",
    "    # Faire la pr√©diction\n",
    "    prediction = model.predict(building_data)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Afficher les features requises pour r√©f√©rence\n",
    "print(\"Features requises pour la pr√©diction:\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"\\nNombre total de features: {len(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple 1: Pr√©diction pour un b√¢timent de bureau typique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√©diction de consommation √©nerg√©tique pour le nouveau b√¢timent: 3581.28 kBtu\n"
     ]
    }
   ],
   "source": [
    "# For a single building\n",
    "new_building = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"NumberofBuildings\": 1,\n",
    "            \"PropertyGFAParking\": 0,\n",
    "            \"PropertyGFABuilding(s)\": 56228,\n",
    "            \"ENERGYSTARScore\": 95,\n",
    "            \"NumberOfUseTypes\": 1,\n",
    "            \"SteamUse\": 0,\n",
    "            \"NaturalGas\": 1,\n",
    "            \"Electricity\": 1,\n",
    "            # Encodage PrimaryPropertyType (placeholders, d√©pend de ton encoder exact)\n",
    "            \"PrimaryPropertyType_0\": 0,\n",
    "            \"PrimaryPropertyType_1\": 0,\n",
    "            \"PrimaryPropertyType_2\": 0,\n",
    "            \"PrimaryPropertyType_3\": 0,\n",
    "            \"PrimaryPropertyType_4\": 0,\n",
    "            # Encodage BuildingType\n",
    "            \"BuildingType_Nonresidential COS\": 0,\n",
    "            \"BuildingType_Nonresidential WA\": 0,\n",
    "            \"BuildingType_SPS-District K-12\": 1,\n",
    "            # NumberofFloors quintiles\n",
    "            \"NumberofFloors_quintile_Q2\": 1,\n",
    "            \"NumberofFloors_quintile_Q3\": 0,\n",
    "            \"NumberofFloors_quintile_Q4\": 0,\n",
    "            \"NumberofFloors_quintile_Q5\": 0,\n",
    "            # EraBuilt\n",
    "            \"EraBuilt_1951-1970\": 1,\n",
    "            \"EraBuilt_1971-1990\": 0,\n",
    "            \"EraBuilt_1991-2010\": 0,\n",
    "            \"EraBuilt_Post-2010\": 0,\n",
    "            \"EraBuilt_‚â§1930\": 0,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "prediction = predict_building_energy(new_building)\n",
    "print(f\"Pr√©diction de consommation √©nerg√©tique pour le nouveau b√¢timent: {prediction[0]:.2f} kBtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OC_P3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
